{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ImW5xLg5Ezyo"
      },
      "outputs": [],
      "source": [
        "# https://huggingface.co/transformers/v3.2.0/custom_datasets.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhjopDg5WeQI"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HNUE5fXIb-W"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "ZLuKyvHJ47xK",
        "outputId": "cdcd5cd5-9af7-4bff-86f3-2e36b1ad6e62"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ed77fc54-f275-4516-8eda-d44996058b41\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Data</th>\n",
              "      <th>Label</th>\n",
              "      <th>translated</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "      <th>review_text_cleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bangka blm bukan kantor pos ambil nya</td>\n",
              "      <td>1</td>\n",
              "      <td>bangka blm bukan kantor pos ambil nya</td>\n",
              "      <td>NaN</td>\n",
              "      <td>bangka belum bukan kantor pos ambil nya</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>halo min apa kpr sudah berjalan bisa minta di...</td>\n",
              "      <td>2</td>\n",
              "      <td>lingkaran cahaya min apa kpr sudah berjalan b...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>lingkaran cahaya min apa kpr sudah berjalan bi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>perancis</td>\n",
              "      <td>1</td>\n",
              "      <td>perancis</td>\n",
              "      <td>NaN</td>\n",
              "      <td>perancis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>kapan giveaway nya nih megamin [smirking face]</td>\n",
              "      <td>0</td>\n",
              "      <td>kapan memberi secara gratis nya nih megamin w...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>kapan memberi secara gratis nya ini megamin wa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>geh yang balam tau gak soto tangkar yang dulu ...</td>\n",
              "      <td>1</td>\n",
              "      <td>geh yang balam tau gak soto tangkar yang dulu...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>geh yang balam tahu tidak soto tangkar yang du...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed77fc54-f275-4516-8eda-d44996058b41')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ed77fc54-f275-4516-8eda-d44996058b41 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ed77fc54-f275-4516-8eda-d44996058b41');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-94da508d-ae5f-4bb6-9460-625ae1407a91\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-94da508d-ae5f-4bb6-9460-625ae1407a91')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-94da508d-ae5f-4bb6-9460-625ae1407a91 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                Data  Label  \\\n",
              "0              bangka blm bukan kantor pos ambil nya      1   \n",
              "1   halo min apa kpr sudah berjalan bisa minta di...      2   \n",
              "2                                          perancis       1   \n",
              "3    kapan giveaway nya nih megamin [smirking face]       0   \n",
              "4  geh yang balam tau gak soto tangkar yang dulu ...      1   \n",
              "\n",
              "                                          translated Unnamed: 3  \\\n",
              "0              bangka blm bukan kantor pos ambil nya        NaN   \n",
              "1   lingkaran cahaya min apa kpr sudah berjalan b...        NaN   \n",
              "2                                           perancis        NaN   \n",
              "3   kapan memberi secara gratis nya nih megamin w...        NaN   \n",
              "4   geh yang balam tau gak soto tangkar yang dulu...        NaN   \n",
              "\n",
              "                                 review_text_cleaned  \n",
              "0            bangka belum bukan kantor pos ambil nya  \n",
              "1  lingkaran cahaya min apa kpr sudah berjalan bi...  \n",
              "2                                           perancis  \n",
              "3  kapan memberi secara gratis nya ini megamin wa...  \n",
              "4  geh yang balam tahu tidak soto tangkar yang du...  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge/data\n",
        "data = pd.read_excel(\"fix_fixed.xlsx\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFpzjJRtGVYq",
        "outputId": "48c481df-0258-477f-d5dc-1f2a767ff7e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5084\n"
          ]
        }
      ],
      "source": [
        "coba = max([len(str(x)) for x in data['review_text_cleaned']])\n",
        "print(coba)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dbrirLG5D0A",
        "outputId": "6703f5c7-aa7e-4e7b-e760-820623c4278f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    18218\n",
              "1     6952\n",
              "2     6829\n",
              "Name: Label, dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['Label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FApLY8Q8HBtF",
        "outputId": "5c219d35-a129-471d-bdaa-e2e57102b1ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.32.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s32nl2kn56cH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "import torch\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AlbertTokenizerFast, AutoModel\n",
        "from transformers import AutoTokenizer, DistilBertForSequenceClassification\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1JlB3eYiV8a",
        "outputId": "bc77a252-f79f-4743-fe3e-483b61b0a8b4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_classification.py:105: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('ayameRushia/bert-base-indonesian-1.5G-sentiment-analysis-smsa')\n",
        "model = BertForSequenceClassification.from_pretrained('ayameRushia/bert-base-indonesian-1.5G-sentiment-analysis-smsa',num_labels=3)\n",
        "classifier = pipeline(\"text-classification\",\n",
        "                      model='ayameRushia/bert-base-indonesian-1.5G-sentiment-analysis-smsa',\n",
        "                      return_all_scores=True)\n",
        "# prediction = classifier(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPKswImmYUjO",
        "outputId": "5434e462-f4d8-4cd4-ce1b-90e42d359e8e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<transformers.pipelines.text_classification.TextClassificationPipeline at 0x7c94e9eda1d0>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCIO165RiZfC"
      },
      "outputs": [],
      "source": [
        "model = model.to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tESWTOfVHEqA"
      },
      "outputs": [],
      "source": [
        "sample_data = [\"kredit mahal\",\"saya suka bank mega\"]\n",
        "test_labels = [2, 1]\n",
        "sample_data_tens = tokenizer(sample_data, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
        "sample_data_tens = {key: value.to('cuda') for key, value in sample_data_tens.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHW0ghV7GVYr",
        "outputId": "f0e33a8f-4075-47fd-c39e-48a7ac0e6e8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data                   object\n",
            "Label                   int64\n",
            "translated             object\n",
            "Unnamed: 3             object\n",
            "review_text_cleaned    object\n",
            "dtype: object\n",
            "\n",
            "Updated data types:\n",
            "Data                   object\n",
            "Label                   int64\n",
            "translated             object\n",
            "Unnamed: 3             object\n",
            "review_text_cleaned    object\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(data.dtypes)\n",
        "# Change the data type of the 'Age' column to float\n",
        "data['review_text_cleaned'] = data['review_text_cleaned'].astype(str)\n",
        "\n",
        "# Display the updated data types of columns\n",
        "print(\"\\nUpdated data types:\")\n",
        "print(data.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrkjJArSGVYr",
        "outputId": "967a474f-72ad-4cdf-fb1a-a463965d614d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max length:  910\n"
          ]
        }
      ],
      "source": [
        "encoded_tweets = [tokenizer.encode(sent, add_special_tokens=True) for sent in data['review_text_cleaned']]\n",
        "\n",
        "# Find the maximum length\n",
        "max_len = max([len(sent) for sent in encoded_tweets])\n",
        "print('Max length: ', max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyWcZBQuid2V"
      },
      "outputs": [],
      "source": [
        "\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "X = list(data[\"review_text_cleaned\"])\n",
        "y = list(data[\"Label\"])\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2,stratify=y)\n",
        "X_train_tokenized = tokenizer(list(X_train), padding=True, truncation=True, max_length=512)\n",
        "X_val_tokenized = tokenizer(list(X_val), padding=True, truncation=True, max_length=512)\n",
        "X_val_tokenized = {key: value for key, value in X_val_tokenized.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ll_YffE1rrKV",
        "outputId": "94fe2f04-705a-4499-aadc-64b5f77a20e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_tokenized.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5TGibGZIAZT",
        "outputId": "f2780e81-d937-43bb-8f2c-8210da8a073f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[3, 2918, 1542, 6431, 1555, 2054, 3122, 29879, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
          ]
        }
      ],
      "source": [
        "print(X_train_tokenized['input_ids'][90])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2bs25fZish6",
        "outputId": "fa3624aa-93ae-4ee4-af59-b642a43c9bd5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(25599, 6400)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(X_train),len(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Dq__AdmjiEh"
      },
      "outputs": [],
      "source": [
        "# Create torch dataset\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels=None):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels:\n",
        "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings[\"input_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52bjWWitkMRw"
      },
      "outputs": [],
      "source": [
        "train_dataset = Dataset(X_train_tokenized, y_train)\n",
        "val_dataset = Dataset(X_val_tokenized, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqrFeE7Trgtd",
        "outputId": "5600f09b-6a4f-4a36-ccae-27400ff6a1d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<__main__.Dataset at 0x7c94dc30efe0>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSYfH_aIkOwf"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "def compute_metrics(p):\n",
        "    pred, labels = p\n",
        "    pred = np.argmax(pred, axis=1)\n",
        "\n",
        "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
        "    recall = recall_score(y_true=labels, y_pred=pred, average='weighted')  # Change 'weighted' or other appropriate value\n",
        "    precision = precision_score(y_true=labels, y_pred=pred, average='weighted')  # Change 'weighted' or other appropriate value\n",
        "    f1 = f1_score(y_true=labels, y_pred=pred, average='weighted')  # Change 'weighted' or other appropriate value\n",
        "\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPmys-_vGVYt"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "# from datasets import load_metric\n",
        "# metric = load_metric('accuracy')\n",
        "\n",
        "# def compute_metrics(eval_pred):\n",
        "#     predictions, labels = eval_pred\n",
        "#     predictions = np.argmax(predictions, axis=1)\n",
        "#     return metric.compute(predictions=predictions, references=labels)\n",
        "class CustomTrainer(Trainer):\n",
        "    def log_metrics(self, metrics, step=None):\n",
        "        logs = {**metrics}\n",
        "        if step is not None:\n",
        "            logs[\"step\"] = step\n",
        "        self.log(logs)\n",
        "# class CustomTrainer(Trainer):\n",
        "#     def compute_loss(self, model, inputs, labels, return_outputs=False):\n",
        "#         inputs = {key: torch.tensor(value).to('cuda') for key, value in inputs.items()}  # Convert inputs to tensors\n",
        "#         labels = torch.tensor(labels).to('cuda')\n",
        "#         print(inputs)\n",
        "#         # Forward pass through the model\n",
        "#         outputs = model(**inputs)\n",
        "\n",
        "#         # Extract the last hidden state from the outputs\n",
        "#         last_hidden_state = outputs.last_hidden_state\n",
        "\n",
        "#         # Apply a linear layer to the last hidden state to get logits\n",
        "#         classifier = nn.Linear(last_hidden_state.shape[-1], 3).to(last_hidden_state.device)  # num_classes is the number of output classes\n",
        "#         logits = classifier(last_hidden_state)\n",
        "\n",
        "#         # Apply softmax to get the predicted probabilities\n",
        "#         predicted_probabilities = nn.functional.softmax(logits, dim=-1)\n",
        "#         print(predicted_probabilities.size())\n",
        "#         # Get the predicted class labels by finding the index of the maximum probability\n",
        "#         predicted_labels = torch.argmax(predicted_probabilities, dim=-1)\n",
        "#         print(predicted_labels.size())\n",
        "#         # Calculate the loss using cross-entropy loss with class weights\n",
        "#         # class_weights = torch.tensor([1.0, 2.0, 3.0], device=model.device)\n",
        "#         loss_fct = nn.CrossEntropyLoss()\n",
        "#         print(predicted_labels.view(-1, predicted_labels.size(-1)).size(),labels.view(-1).size())\n",
        "#         loss = loss_fct(predicted_labels.view(-1, predicted_labels.size(-1)), labels.view(-1))\n",
        "#         print(loss.backward())\n",
        "#         # Print the results\n",
        "#         print(\"Predicted Probabilities:\", predicted_probabilities)\n",
        "#         print(\"Predicted Labels:\", predicted_labels)\n",
        "#         print(\"Loss:\", loss.item())\n",
        "\n",
        "#         return (loss, predicted_labels) if return_outputs else loss\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FlwB8C5VSAxn"
      },
      "outputs": [],
      "source": [
        "class MyModel(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.bert = BertForSequenceClassification.from_pretrained('ayameRushia/bert-base-indonesian-1.5G-sentiment-analysis-smsa')\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        logits = outputs.logits\n",
        "        loss = outputs.loss if labels is not None else None\n",
        "        return {\"logits\": logits, \"loss\": loss}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YGtn1arUnWV",
        "outputId": "797698ef-e7da-47ea-e882-e3f72f690cb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.22.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "id": "vFcXgFFNkRDP",
        "outputId": "fbabd1cb-5ff7-4f60-dc2d-e354d55dffe8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1201' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1201/8000 1:48:36 < 10:15:51, 0.18 it/s, Epoch 0.75/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.312100</td>\n",
              "      <td>0.676318</td>\n",
              "      <td>0.713750</td>\n",
              "      <td>0.693103</td>\n",
              "      <td>0.713750</td>\n",
              "      <td>0.688276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.691900</td>\n",
              "      <td>0.627476</td>\n",
              "      <td>0.739844</td>\n",
              "      <td>0.727589</td>\n",
              "      <td>0.739844</td>\n",
              "      <td>0.726266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.624400</td>\n",
              "      <td>0.602664</td>\n",
              "      <td>0.743906</td>\n",
              "      <td>0.751269</td>\n",
              "      <td>0.743906</td>\n",
              "      <td>0.741497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.611200</td>\n",
              "      <td>0.566809</td>\n",
              "      <td>0.765625</td>\n",
              "      <td>0.757350</td>\n",
              "      <td>0.765625</td>\n",
              "      <td>0.757085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.615000</td>\n",
              "      <td>0.575515</td>\n",
              "      <td>0.762031</td>\n",
              "      <td>0.773424</td>\n",
              "      <td>0.762031</td>\n",
              "      <td>0.766298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.603000</td>\n",
              "      <td>0.553771</td>\n",
              "      <td>0.771563</td>\n",
              "      <td>0.763210</td>\n",
              "      <td>0.771563</td>\n",
              "      <td>0.758572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.577500</td>\n",
              "      <td>0.569431</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>0.764834</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>0.761917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.582700</td>\n",
              "      <td>0.554137</td>\n",
              "      <td>0.767031</td>\n",
              "      <td>0.781654</td>\n",
              "      <td>0.767031</td>\n",
              "      <td>0.772069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.596300</td>\n",
              "      <td>0.562172</td>\n",
              "      <td>0.765156</td>\n",
              "      <td>0.769286</td>\n",
              "      <td>0.765156</td>\n",
              "      <td>0.763125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.618700</td>\n",
              "      <td>0.523946</td>\n",
              "      <td>0.779062</td>\n",
              "      <td>0.770847</td>\n",
              "      <td>0.779062</td>\n",
              "      <td>0.765573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.524800</td>\n",
              "      <td>0.523569</td>\n",
              "      <td>0.780312</td>\n",
              "      <td>0.772515</td>\n",
              "      <td>0.780312</td>\n",
              "      <td>0.769673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.605000</td>\n",
              "      <td>0.525606</td>\n",
              "      <td>0.773281</td>\n",
              "      <td>0.765449</td>\n",
              "      <td>0.773281</td>\n",
              "      <td>0.763533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.533000</td>\n",
              "      <td>0.536822</td>\n",
              "      <td>0.776875</td>\n",
              "      <td>0.789778</td>\n",
              "      <td>0.776875</td>\n",
              "      <td>0.780120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.566200</td>\n",
              "      <td>0.521178</td>\n",
              "      <td>0.782813</td>\n",
              "      <td>0.778316</td>\n",
              "      <td>0.782813</td>\n",
              "      <td>0.774726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.552000</td>\n",
              "      <td>0.565325</td>\n",
              "      <td>0.777969</td>\n",
              "      <td>0.769763</td>\n",
              "      <td>0.777969</td>\n",
              "      <td>0.766093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.552300</td>\n",
              "      <td>0.525813</td>\n",
              "      <td>0.783750</td>\n",
              "      <td>0.776148</td>\n",
              "      <td>0.783750</td>\n",
              "      <td>0.771366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.553700</td>\n",
              "      <td>0.507117</td>\n",
              "      <td>0.787813</td>\n",
              "      <td>0.779757</td>\n",
              "      <td>0.787813</td>\n",
              "      <td>0.779290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.511600</td>\n",
              "      <td>0.516863</td>\n",
              "      <td>0.785625</td>\n",
              "      <td>0.784906</td>\n",
              "      <td>0.785625</td>\n",
              "      <td>0.785224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.552100</td>\n",
              "      <td>0.506054</td>\n",
              "      <td>0.795781</td>\n",
              "      <td>0.788210</td>\n",
              "      <td>0.795781</td>\n",
              "      <td>0.786724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.548100</td>\n",
              "      <td>0.505842</td>\n",
              "      <td>0.788281</td>\n",
              "      <td>0.788317</td>\n",
              "      <td>0.788281</td>\n",
              "      <td>0.785664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.530500</td>\n",
              "      <td>0.518525</td>\n",
              "      <td>0.784844</td>\n",
              "      <td>0.796113</td>\n",
              "      <td>0.784844</td>\n",
              "      <td>0.788236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.524700</td>\n",
              "      <td>0.521813</td>\n",
              "      <td>0.784687</td>\n",
              "      <td>0.778845</td>\n",
              "      <td>0.784687</td>\n",
              "      <td>0.774060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.547500</td>\n",
              "      <td>0.507889</td>\n",
              "      <td>0.793438</td>\n",
              "      <td>0.791858</td>\n",
              "      <td>0.793438</td>\n",
              "      <td>0.792387</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='29' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 29/400 00:14 < 03:09, 1.96 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Define Trainer\n",
        "# args = TrainingArguments(\n",
        "#     output_dir=\"output\",\n",
        "#     num_train_epochs=1,\n",
        "#     per_device_train_batch_size=16\n",
        "\n",
        "# )\n",
        "# trainer = Trainer(\n",
        "#     model=model,\n",
        "#     args=args,\n",
        "#     train_dataset=train_dataset,\n",
        "#     eval_dataset=val_dataset,\n",
        "#     compute_metrics=compute_metrics\n",
        "# )\n",
        "from transformers import EarlyStoppingCallback, IntervalStrategy\n",
        "model = MyModel(num_classes=3)\n",
        "\n",
        "# Set up training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=50,\n",
        "    save_total_limit=2,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    learning_rate=2e-05,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.01,\n",
        "    save_steps=500,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=50,\n",
        "    metric_for_best_model = 'f1',\n",
        "    load_best_model_at_end=True\n",
        ")\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = CustomTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,  # Replace with your training dataset\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks = [EarlyStoppingCallback(early_stopping_patience=2)]# Replace with your evaluation dataset\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "# trainer.train()\n",
        "\n",
        "# training_args = TrainingArguments(\n",
        "#     num_train_epochs=1,\n",
        "#     output_dir='./results',\n",
        "#     evaluation_strategy=\"steps\",\n",
        "#     eval_steps=500,\n",
        "#     save_total_limit=2,\n",
        "#     per_device_train_batch_size=16,\n",
        "#     per_device_eval_batch_size=16,\n",
        "#     learning_rate=2e-05,\n",
        "#     save_steps=500,\n",
        "#     logging_dir='./logs',\n",
        "#     logging_steps=100,\n",
        "#     seed = 42\n",
        "# )\n",
        "# trainer = Trainer(\n",
        "#     model=model,\n",
        "#     args=training_args,\n",
        "#     train_dataset=train_dataset,  # Replace with your training dataset\n",
        "#     eval_dataset=val_dataset   # Replace with your evaluation dataset\n",
        "#     # Replace with your data collator\n",
        "# )\n",
        "\n",
        "# Train the model\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ia14Y_UmN7qM"
      },
      "outputs": [],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owBTtpMkPm0l"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(trainer.state.log_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfEfsnNvnOD0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
